# -*- coding: utf-8 -*-
"""Test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HDY2PP0qJOboCjsCzbvOYow0UjcQfHU1
"""

#How to interact with LLMs

#1. API Key
#2. Model name
#3. Prompt
#4. SDK or framework



import os
#from google.colab import userdata
#os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')
# pyright: ignore[reportMissingImports]
from dotenv import load_dotenv
load_dotenv()
api_key = os.getenv('GOOGLE_API_KEY')
#Langchain

# Commented out IPython magic to ensure Python compatibility.
# %pip install -qU "langchain[google-genai]"

from langchain.chat_models import init_chat_model

llm = init_chat_model(model="gemini-2.5-flash", model_provider="google_genai")

messages="What should be the purpose of life?"

response=llm.invoke(messages)

print (response.content)